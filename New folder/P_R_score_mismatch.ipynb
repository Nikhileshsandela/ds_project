{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P/R score mismatch.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xPuOxbbV2rk",
        "colab_type": "code",
        "outputId": "f798ec16-ba47-48ec-8988-cc89e83395f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "learning_rate = 0.1\n",
        "train_steps = 5000\n",
        "\n",
        "class MNISTDataset:\n",
        "    \"\"\"'Bare minimum' class to wrap MNIST numpy arrays into a dataset.\"\"\"\n",
        "    def __init__(self, train_imgs, train_lbs, test_imgs, test_lbls, batch_size,\n",
        "                 to01=True, shuffle=True, seed=None,pad_bias=True):\n",
        "        \"\"\"\n",
        "        Use seed optionally to always get the same shuffling (-> reproducible\n",
        "        results).\n",
        "        \"\"\"\n",
        "        self.num_samples,self.num_features = np.shape(train_imgs)\n",
        "        self.batch_size = batch_size\n",
        "        \n",
        "        if not pad_bias:\n",
        "          self.train_data = train_imgs\n",
        "        else:\n",
        "          self.train_data = np.c_[train_imgs , np.ones(self.num_samples)* 255]\n",
        "        \n",
        "        self.train_labels = train_lbs.astype(np.int32)\n",
        "        self.test_data = test_imgs\n",
        "        self.test_labels = test_lbls.astype(np.int32)\n",
        "\n",
        "        if to01:\n",
        "            # int in [0, 255] -> float in [0, 1]\n",
        "            self.train_data = self.train_data.astype(np.float32) / 255\n",
        "            self.test_data = self.test_data.astype(np.float32) / 255\n",
        "\n",
        "        self.size = self.train_data.shape[0]\n",
        "\n",
        "        if seed:\n",
        "            np.random.seed(seed)\n",
        "        if shuffle:\n",
        "            self.shuffle_train()\n",
        "        self.shuffle = shuffle\n",
        "        self.current_pos = 0\n",
        "\n",
        "    def next_batch(self):\n",
        "        \"\"\"Either gets the next batch, or optionally shuffles and starts a\n",
        "        new epoch.\"\"\"\n",
        "        end_pos = self.current_pos + self.batch_size\n",
        "        if end_pos < self.size:\n",
        "            batch = (self.train_data[self.current_pos:end_pos],\n",
        "                     self.train_labels[self.current_pos:end_pos])\n",
        "            self.current_pos += self.batch_size\n",
        "        else:\n",
        "            # we return what's left (-> possibly smaller batch!) and prepare\n",
        "            # the start of a new epoch\n",
        "            batch = (self.train_data[self.current_pos:self.size],\n",
        "                     self.train_labels[self.current_pos:self.size])\n",
        "            if self.shuffle:\n",
        "                self.shuffle_train()\n",
        "            self.current_pos = 0\n",
        "            print(\"Starting new epoch...\")\n",
        "        return batch\n",
        "\n",
        "    def shuffle_train(self):\n",
        "        shuffled_inds = np.arange(self.train_data.shape[0])\n",
        "        np.random.shuffle(shuffled_inds)\n",
        "        self.train_data = self.train_data[shuffled_inds]\n",
        "        self.train_labels = self.train_labels[shuffled_inds]\n",
        "\n",
        "fmnist_labels = {\n",
        "0: \"T-shirt/top\",\n",
        "1:\t\"Trouser\",\n",
        "2:\t\"Pullover\",\n",
        "3:\t\"Dress\",\n",
        "4:\t\"Coat\",\n",
        "5:\t\"Sandal\",\n",
        "6:\t\"Shirt\",\n",
        "7:\t\"Sneaker\",\n",
        "8:\t\"Bag\",\n",
        "9:\t\"Ankle boot\"\n",
        "}\n",
        "\n",
        "#Fetch data\n",
        "mnist =  tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "data = MNISTDataset(train_images.reshape([-1, 784]), train_labels, \n",
        "                    test_images.reshape([-1, 784]), test_labels,\n",
        "                    batch_size=128,pad_bias=False, seed = 1807)\n",
        "\n",
        "# Training the network\n",
        "def random_initial_weight_matrix(x,y=None,epsilon=0.18,bias=False):\n",
        "  \n",
        "  if not bias:\n",
        "    theta = (np.random.rand(x, y).astype(np.float32)* 2 * epsilon) - epsilon\n",
        "    # theta = np.zeros([x,y],dtype=np.float32)\n",
        "  else:\n",
        "    # theta = np.zeros(x,dtype=np.float32)\n",
        "    theta = (np.random.rand(x).astype(np.float32) * 2 * epsilon) - epsilon\n",
        "  \n",
        "  theta = tf.Variable(theta)\n",
        "  return theta\n",
        "\n",
        "riwm = lambda x,y : random_initial_weight_matrix(x,y)\n",
        "ribm = lambda x,y : random_initial_weight_matrix(x,y,bias=True)\n",
        "\n",
        "layer_config = {\n",
        "    \"in\":784,\n",
        "    \"hidden\":[200,50],\n",
        "    \"out\": 10\n",
        "}\n",
        "\n",
        "W = [\n",
        "     riwm(layer_config[\"in\"],layer_config[\"hidden\"][0]),\n",
        "     riwm(layer_config[\"hidden\"][0],layer_config[\"hidden\"][1]),\n",
        "     riwm(layer_config[\"hidden\"][1],layer_config[\"out\"])\n",
        "    ]\n",
        "\n",
        "b = [\n",
        "     ribm(layer_config[\"hidden\"][0],1),\n",
        "     ribm(layer_config[\"hidden\"][1],1),\n",
        "     ribm(layer_config[\"out\"],1)\n",
        "    ]\n",
        "\n",
        "record = {\n",
        "    \"train_cross_ent\": [], \n",
        "    \"weight\": [\n",
        "    ],\n",
        "    \"bias\" : [\n",
        "\n",
        "    ],\n",
        "    \"train_accuracy\": []\n",
        "}\n",
        "\n",
        "for step in range(train_steps):\n",
        "    img_batch, lbl_batch = data.next_batch()\n",
        "    hyp = [\n",
        "           [],\n",
        "           [],\n",
        "           []\n",
        "    ]\n",
        "    act = [\n",
        "           [],\n",
        "           [],\n",
        "           []\n",
        "    ]\n",
        "    activation = [tf.nn.relu,tf.nn.relu,tf.nn.softmax]\n",
        "    with tf.GradientTape() as tape:\n",
        "        hyp[0] = tf.matmul(img_batch,W[0]) + b[0]\n",
        "        act[0] = activation[0](hyp[0])\n",
        "\n",
        "        hyp[1] = tf.matmul(act[0],W[1]) + b[1]\n",
        "        act[1] = activation[1](hyp[1]) \n",
        "\n",
        "        hyp[2] = tf.matmul(act[1],W[2]) + b[2]\n",
        "        act[2] = activation[2](hyp[2])\n",
        "\n",
        "        xent = tf.reduce_mean(\n",
        "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "                labels = lbl_batch, logits = hyp[-1]))\n",
        "        \n",
        "        preds = tf.argmax(act[-1], axis=1, output_type=tf.int32)\n",
        "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
        "                             tf.float32))\n",
        "        \n",
        "        record[\"train_cross_ent\"].append(xent)\n",
        "        record[\"train_accuracy\"].append(acc)\n",
        "        # record[\"activation\"][0].append(act[0])\n",
        "        # record[\"activation\"][1].append(act[1])\n",
        "        # record[\"activation\"][2].append(act[2])\n",
        "\n",
        "    #backprop time   \n",
        "    grads = tape.gradient(xent, [W[0], b[0], W[1], b[1], W[2], b[2]])\n",
        "    \n",
        "    W[0].assign_sub(learning_rate * grads[0])\n",
        "    b[0].assign_sub(learning_rate * grads[1])\n",
        "\n",
        "    W[1].assign_sub(learning_rate * grads[2])\n",
        "    b[1].assign_sub(learning_rate * grads[3])\n",
        "    \n",
        "    W[2].assign_sub(learning_rate * grads[4])\n",
        "    b[2].assign_sub(learning_rate * grads[5])\n",
        "\n",
        "    record[\"weight\"].append(W)\n",
        "    record[\"bias\"].append(b)\n",
        "\n",
        "\n",
        "    if not step % 300:\n",
        "        print(\"Loss: {} Accuracy: {}, step: {}\".format(xent, acc,step))\n",
        "\n",
        "def test_model(y_data,y_labels,_W,_b,_idx):\n",
        "  # Load any of these two model weights, and do a forward pass to get test \n",
        "  #results\n",
        "  # print(\"test examples, \",np.shape(data.test_data))\n",
        "  # weights = best_model_weights[-1]\n",
        "  assert len(y_data) == len(y_labels)\n",
        "  _hyp = [\n",
        "        [],\n",
        "        [],\n",
        "        []\n",
        "  ]\n",
        "  _act = [\n",
        "        [],\n",
        "        [],\n",
        "        []\n",
        "  ]\n",
        "  _activation = [tf.nn.relu,tf.nn.relu,tf.nn.softmax]\n",
        "  \n",
        "  _hyp[0] = tf.matmul(y_data,_W[0])+ _b[0]\n",
        "  _act[0] = _activation[0](_hyp[0])\n",
        "  \n",
        "  _hyp[1] = tf.matmul(_act[0],_W[1]) + _b[1]\n",
        "  _act[1] = _activation[1](_hyp[1]) \n",
        "\n",
        "  _hyp[2] = tf.matmul(_act[1],_W[2]) + _b[2]\n",
        "  _act[2] = _activation[2](_hyp[2])\n",
        "\n",
        "  test_preds = tf.argmax(_act[2], axis=1,\n",
        "                        output_type=tf.int32)\n",
        "  test_preds = np.array(test_preds)\n",
        "\n",
        "  test_acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, y_labels),\n",
        "                              tf.float32))\n",
        "  result = f'Test accuracy {test_acc*100:.3f}% with model #{idx}'\n",
        "  # print(f'Test accuracy {test_acc*100:.3f}% with model #{idx}')\n",
        "  return test_preds,result\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss: 2.6577274799346924 Accuracy: 0.1640625, step: 0\n",
            "Loss: 0.6323590278625488 Accuracy: 0.765625, step: 300\n",
            "Starting new epoch...\n",
            "Loss: 0.5289076566696167 Accuracy: 0.8125, step: 600\n",
            "Loss: 0.4538968503475189 Accuracy: 0.8671875, step: 900\n",
            "Starting new epoch...\n",
            "Loss: 0.41634881496429443 Accuracy: 0.828125, step: 1200\n",
            "Starting new epoch...\n",
            "Loss: 0.4013941287994385 Accuracy: 0.84375, step: 1500\n",
            "Loss: 0.4404841363430023 Accuracy: 0.859375, step: 1800\n",
            "Starting new epoch...\n",
            "Loss: 0.33555006980895996 Accuracy: 0.890625, step: 2100\n",
            "Starting new epoch...\n",
            "Loss: 0.4095020890235901 Accuracy: 0.8359375, step: 2400\n",
            "Loss: 0.2784830331802368 Accuracy: 0.8984375, step: 2700\n",
            "Starting new epoch...\n",
            "Loss: 0.37234389781951904 Accuracy: 0.8515625, step: 3000\n",
            "Starting new epoch...\n",
            "Loss: 0.32758259773254395 Accuracy: 0.875, step: 3300\n",
            "Loss: 0.36581453680992126 Accuracy: 0.828125, step: 3600\n",
            "Starting new epoch...\n",
            "Loss: 0.19113998115062714 Accuracy: 0.953125, step: 3900\n",
            "Loss: 0.3525354266166687 Accuracy: 0.9140625, step: 4200\n",
            "Starting new epoch...\n",
            "Loss: 0.27382898330688477 Accuracy: 0.8828125, step: 4500\n",
            "Starting new epoch...\n",
            "Loss: 0.25016331672668457 Accuracy: 0.8984375, step: 4800\n",
            "Test accuracy 85.070% with model #4999\n",
            "\n",
            "\n",
            "T-shirt/top : Precision 0.8452631578947368, Recall 0.803\n",
            "Trouser : Precision 0.9907407407407407, Recall 0.963\n",
            "Pullover : Precision 0.8249075215782984, Recall 0.669\n",
            "Dress : Precision 0.8311444652908068, Recall 0.886\n",
            "Coat : Precision 0.65, Recall 0.91\n",
            "Sandal : Precision 0.9846153846153847, Recall 0.896\n",
            "Shirt : Precision 0.7296587926509186, Recall 0.556\n",
            "Sneaker : Precision 0.8117839607201309, Recall 0.992\n",
            "Bag : Precision 0.941747572815534, Recall 0.97\n",
            "Ankle boot : Precision 0.9828962371721779, Recall 0.862\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e082ac49f0fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    238\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{fmnist_labels[i]} : Precision {p_r_score[0][i]}, Recall {p_r_score[1][i]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m print(classification_report(data.test_labels,preds,           # gives 0 p/r scores?\n\u001b[0;32m--> 240\u001b[0;31m                           labels=fmnist_labels.keys()))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     micro_is_accuracy = ((y_type == 'multiclass' or y_type == 'binary') and\n\u001b[1;32m   1982\u001b[0m                          (not labels_given or\n\u001b[0;32m-> 1983\u001b[0;31m                           (set(labels) == set(unique_labels(y_true, y_pred)))))\n\u001b[0m\u001b[1;32m   1984\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: iteration over a 0-d array"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0m6p8fKV6TP",
        "colab_type": "code",
        "outputId": "d898b17e-46e0-437a-8a0e-f612659c6eef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "W = record[\"weight\"][-1]\n",
        "idx = len(record[\"weight\"]) - 1\n",
        "b = record[\"bias\"][idx]\n",
        "preds,result = test_model(data.test_data,data.test_labels,W,b,idx)\n",
        "print(result)\n",
        "p_r_score = (precision_recall_fscore_support(data.test_labels,preds)[0:2])\n",
        "print(\"\\n\")\n",
        "for i in range(len(p_r_score[0])):\n",
        "  print(f'{fmnist_labels[i]} : Precision {p_r_score[0][i]}, Recall {p_r_score[1][i]}')\n",
        "print(classification_report(data.test_labels,preds,           # gives 0 p/r scores?\n",
        "                          labels=list(fmnist_labels.keys()),target_names=[\n",
        "                                                                          fmnist_labels[key] for key in fmnist_labels\n",
        "                          ]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy 85.070% with model #4999\n",
            "\n",
            "\n",
            "T-shirt/top : Precision 0.8452631578947368, Recall 0.803\n",
            "Trouser : Precision 0.9907407407407407, Recall 0.963\n",
            "Pullover : Precision 0.8249075215782984, Recall 0.669\n",
            "Dress : Precision 0.8311444652908068, Recall 0.886\n",
            "Coat : Precision 0.65, Recall 0.91\n",
            "Sandal : Precision 0.9846153846153847, Recall 0.896\n",
            "Shirt : Precision 0.7296587926509186, Recall 0.556\n",
            "Sneaker : Precision 0.8117839607201309, Recall 0.992\n",
            "Bag : Precision 0.941747572815534, Recall 0.97\n",
            "Ankle boot : Precision 0.9828962371721779, Recall 0.862\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " T-shirt/top       0.85      0.80      0.82      1000\n",
            "     Trouser       0.99      0.96      0.98      1000\n",
            "    Pullover       0.82      0.67      0.74      1000\n",
            "       Dress       0.83      0.89      0.86      1000\n",
            "        Coat       0.65      0.91      0.76      1000\n",
            "      Sandal       0.98      0.90      0.94      1000\n",
            "       Shirt       0.73      0.56      0.63      1000\n",
            "     Sneaker       0.81      0.99      0.89      1000\n",
            "         Bag       0.94      0.97      0.96      1000\n",
            "  Ankle boot       0.98      0.86      0.92      1000\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.86      0.85      0.85     10000\n",
            "weighted avg       0.86      0.85      0.85     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrVf58xLyGb_",
        "colab_type": "code",
        "outputId": "c46d7e4d-a374-4d47-dfe7-0a6d82f32b33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fmnist_labels.keys()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALqvNnvyG3z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}