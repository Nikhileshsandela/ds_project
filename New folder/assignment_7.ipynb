{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment_7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NpEF_YltWax",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKrMZQ8vtIX-",
        "colab_type": "code",
        "outputId": "00e01b49-4f64-47d8-f576-5decfae7be93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAICf67txLZ-",
        "colab_type": "text"
      },
      "source": [
        "**1. Given a 2D tensor of shape (?, n), extract the k (k <= n) highest values for each row into a tensor of shape (?, k). Hint: There might be a function to get the “top k” values of a tensor.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeaT81DUtYGF",
        "colab_type": "code",
        "outputId": "2543141d-2c89-4073-9baa-234631fa2844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# can create tensors using numpy\n",
        "# np_array = np.arange(0, 20,dtype=float).reshape(5, 4)\n",
        "# tens_array = tf.constant(np_array)\n",
        "\n",
        "# or directly as follows\n",
        "tens_array = tf.Variable(tf.range(0, 20, 1, dtype=float))\n",
        "tens_array = tf.reshape(tens_array, shape=(5, -1))\n",
        "tens_array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.],\n",
              "       [16., 17., 18., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yG5yAAA_oRl2",
        "colab_type": "code",
        "outputId": "53c75c66-2b0f-461a-c02c-0d12d612b43f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max_values = tf.reduce_max(tens_array, axis=1)\n",
        "max_values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 3.,  7., 11., 15., 19.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "936oeFVjxefe",
        "colab_type": "text"
      },
      "source": [
        "**2. Given a tensor of shape (?, n), find the argmax in each row and return a new tensor that contains a 1 in each of the argmax’ positions, and 0s everywhere else.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSBwxLL4s7cb",
        "colab_type": "code",
        "outputId": "74782734-a933-480e-885a-eed02e4ba7d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# creating array of argmax row-wise\n",
        "max_index = tf.Variable(tf.argmax(tens_array, axis=0))\n",
        "max_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(4,) dtype=int64, numpy=array([4, 4, 4, 4])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgjrpsTFTokS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tens_zeros = tf.zeros_like(tens_array)\n",
        "new_tens_ones = tf.ones_like(tens_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imFw_zK4ToiN",
        "colab_type": "code",
        "outputId": "7de37f14-5ccf-43fb-f263-3a05a243acb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.where(tf.equal(tens_array[0],max_values[0]), new_tens_ones, new_tens_zeros)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi6vO0gCxmE1",
        "colab_type": "text"
      },
      "source": [
        "**3. As in 1., but instead of “extracting” the top k values, create a new tensor with shape (?, n) where all but the top k values for each row are zero. Try doing this with a 1D tensor of shape (n,) (i.e. one row) first. Getting it right for a 2D tensor is more tricky; consider this a bonus. Hint: You should look for a way to “scatter” a tensor of values into a different tensor. For two or more dimensions, you need to think carefully about the indices.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TQ9Xskcxqre",
        "colab_type": "code",
        "outputId": "52446496-4f28-4dff-ba6b-bd0a0153f01a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tens_array = tf.Variable(tf.range(0, 20, 1, dtype=float))\n",
        "tens_array = tf.reshape(tens_array, shape=(5, -1))\n",
        "tens_array"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  1.,  2.,  3.],\n",
              "       [ 4.,  5.,  6.,  7.],\n",
              "       [ 8.,  9., 10., 11.],\n",
              "       [12., 13., 14., 15.],\n",
              "       [16., 17., 18., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNfKooVqHa9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_tens_zeros = tf.zeros_like(tens_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ODkblfbJH6k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_values = tf.reduce_max(tens_array, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nFDXXMKHbNP",
        "colab_type": "code",
        "outputId": "d809da98-0657-40a1-bec0-dcb10f75d579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "tf.where(tf.equal(tens_array[0],max_values[0]), tens_array, new_tens_zeros)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[ 0.,  0.,  0.,  3.],\n",
              "       [ 0.,  0.,  0.,  7.],\n",
              "       [ 0.,  0.,  0., 11.],\n",
              "       [ 0.,  0.,  0., 15.],\n",
              "       [ 0.,  0.,  0., 19.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAxaMi7sxzZl",
        "colab_type": "text"
      },
      "source": [
        "**4. Implement an exponential moving average. That is, given a decay rate a and an input tensor of length T, create a new length T tensor where new[0] = input[0] and new[t] = a * new[t-1] + (1-a) * input[t] otherwise. Do not use tf.train.ExponentialMovingAverage.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9vpI2Emx_kN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnG5TpbLyA-C",
        "colab_type": "text"
      },
      "source": [
        "**5. Find a way to return the last element in 4. without using loops. That is, return new[T] only – you don’t need to compute the other time steps (if you can avoid it).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4btEETLbyFHs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ixTW15-yF8s",
        "colab_type": "text"
      },
      "source": [
        "**6. Given three integer tensors x, y, z all of the same (arbitrary) shape, create a new tensor that takes values from y where x is even and from z where x is odd.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLF22QW1yJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nq5wqo0lyOdT",
        "colab_type": "text"
      },
      "source": [
        "**7. Given a tensor of arbitrary and unknown shape (but at least one dimension), return 100 if the last dimension has size > 100, 12 if the last dimension has size <= 100 and > 44, and return 0 otherwise.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwoabN7LyQeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xf9zpEbwyUTL",
        "colab_type": "text"
      },
      "source": [
        "**8. As 7., but also create three global counts (integers), where count i should grow by 1 if condition i happened. Run the function from 7. multiple times to test whether your counting works. Now, add a @tf.function decorator to the function from 7. Does your counter still work? If not, why not? Can you change it so it does work?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3pi7DNnyWZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NkUqTvLyW7Y",
        "colab_type": "text"
      },
      "source": [
        "**9. Given two 1D tensors of equal length n, create a tensor of shape (n, n) where element i,j is the ith element of the first tensor minus the jth element of the second tensor. No loops! Hint: Tensorflow supports broadcasting much like numpy.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LebwnC6qybIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5TRhZiYyezK",
        "colab_type": "text"
      },
      "source": [
        "**10. Implement dot product attention: You are given a sequence of encoder states h of shape batch x time x features and the last decoder state s of shape batch x features. Compute the attention weights alpha where alpha[:, i] is equal to h[:, i] * s where * is the dot product between vectors (in this case we also have a batch dimension so the dot product should be between the corresponding vectors within the batch). That is, alpha should be of shape batch x time and alpha[:, i] should contain the attention weights for encoder time step i.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bszpwRo3yg8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}