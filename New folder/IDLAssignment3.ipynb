{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x12e72b510>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_labels[5])\n",
    "plt.imshow(train_images[5], cmap=\"Greys_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data to (28,28,1)\n",
    "# 1 is the nubmer of channels. MNIST is greyscale image.\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (train_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, train_labels.astype(np.int32)))\n",
    "data = data.shuffle(buffer_size=60000)\n",
    "data = data.batch(128)\n",
    "data = data.repeat()\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (test_images.reshape([-1, 28, 28, 1]).astype(np.float32) / 255, test_labels.astype(np.int32)))\n",
    "test_data = test_data.batch(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               401664    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 440,650\n",
      "Trainable params: 440,650\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# tf.keras.layers.Conv2D(\n",
    "#     filters, kernel_size, strides=(1, 1), padding='valid', data_format=None,\n",
    "#     dilation_rate=(1, 1), activation=None, use_bias=True,\n",
    "#     kernel_initializer='glorot_uniform', bias_initializer='zeros',\n",
    "#     kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\n",
    "#     kernel_constraint=None, bias_constraint=None, **kwargs\n",
    "# )\n",
    "\n",
    "# tf.keras.layers.MaxPool2D(\n",
    "#     pool_size=(2, 2), strides=None, padding='valid', data_format=None, **kwargs\n",
    "# )\n",
    "\n",
    "# tf.keras.layers.Dense(\n",
    "#     units, activation=None, use_bias=True, kernel_initializer='glorot_uniform',\n",
    "#     bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None,\n",
    "#     activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\n",
    "#     **kwargs\n",
    "# )\n",
    "\n",
    "train_steps = 1000\n",
    "input_shape = (28, 28, 1)\n",
    "model = tf.keras.Sequential()\n",
    "# Conv layer 1\n",
    "model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "# conv layer 2\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "# flatten the layer to 7*7*32 = 1568\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# Dense layer 1\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# Dense layer 2\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "# Adam makes things much smoother\n",
    "opt = tf.optimizers.Adam()\n",
    "# from_logits = True!! #neverforget\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.2937443256378174 Accuracy: 0.140625\n",
      "Loss: 0.2761182188987732 Accuracy: 0.890625\n",
      "Loss: 0.1754944920539856 Accuracy: 0.9453125\n",
      "Loss: 0.12722429633140564 Accuracy: 0.96875\n",
      "Loss: 0.0945708155632019 Accuracy: 0.9765625\n",
      "Loss: 0.10193199664354324 Accuracy: 0.9765625\n",
      "Loss: 0.08609023690223694 Accuracy: 0.984375\n",
      "Loss: 0.060191020369529724 Accuracy: 0.96875\n",
      "Loss: 0.05293823778629303 Accuracy: 0.984375\n",
      "Loss: 0.04334782063961029 Accuracy: 0.984375\n",
      "Loss: 0.01373979076743126 Accuracy: 0.9921875\n"
     ]
    }
   ],
   "source": [
    "for step, (img_batch, lbl_batch) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(img_batch)\n",
    "        xent = loss_fn(lbl_batch, logits)\n",
    "\n",
    "    varis = model.trainable_variables\n",
    "    grads = tape.gradient(xent, varis)\n",
    "      \n",
    "    opt.apply_gradients(zip(grads, varis))\n",
    "    \n",
    "    if not step % 100:\n",
    "        preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
    "        acc = tf.reduce_mean(tf.cast(tf.equal(preds, lbl_batch),\n",
    "                             tf.float32))\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.9858999848365784\n"
     ]
    }
   ],
   "source": [
    "test_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "for img_batch, lbl_batch in test_data:\n",
    "    test_acc_metric(lbl_batch, model(img_batch))\n",
    "print(\"Test acc: {}\".format(test_acc_metric.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN - CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 184s 1us/step\n",
      "Train Data : (50000, 32, 32, 3)\n",
      "Test Data : (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print('Train Data : {}'.format(x_train.shape))\n",
    "print('Test Data : {}'.format(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 32, 32, 3), (None, 1)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape data to (32,32,3)\n",
    "# 3 is the nubmer of channels. CIFAR-10 is RGB image.\n",
    "data = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, y_train.astype(np.int32)))\n",
    "data = data.shuffle(buffer_size=60000)\n",
    "data = data.batch(128)\n",
    "data = data.repeat()\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_test.reshape([-1, 32, 32, 3]).astype(np.float32) / 255, y_test.astype(np.int32)))\n",
    "test_data.batch(128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_34 (Conv2D)           (None, 32, 32, 16)        448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 16, 16, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 8, 8, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 320,170\n",
      "Trainable params: 320,170\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_steps = 2000\n",
    "input_shape = (32, 32, 3)\n",
    "model = tf.keras.Sequential()\n",
    "# Conv layer 1\n",
    "model.add(tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "# conv layer 2\n",
    "model.add(tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "# conv layer 2\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='same'))\n",
    "# flatten the layer to 4*4*64 = 1024\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "# Dense layer 1\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "# Dense layer 2\n",
    "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "\n",
    "# Adam makes things much smoother\n",
    "opt = tf.optimizers.Adam()\n",
    "# from_logits = True!! #neverforget\n",
    "loss_fn = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3014140129089355 Accuracy: 0.15625\n",
      "Loss: 1.631751298904419 Accuracy: 0.28914061188697815\n",
      "Loss: 1.6310293674468994 Accuracy: 0.41664063930511475\n",
      "Loss: 1.5136134624481201 Accuracy: 0.46851563453674316\n",
      "Loss: 1.4831602573394775 Accuracy: 0.49600061774253845\n",
      "Loss: 1.2786078453063965 Accuracy: 0.5346875190734863\n",
      "Loss: 1.1395777463912964 Accuracy: 0.5584375262260437\n",
      "Loss: 1.0621386766433716 Accuracy: 0.5821874737739563\n",
      "Loss: 0.9748655557632446 Accuracy: 0.5984159111976624\n",
      "Loss: 1.0792893171310425 Accuracy: 0.6181250214576721\n",
      "Loss: 0.9928085803985596 Accuracy: 0.6241406202316284\n",
      "Loss: 0.9429254531860352 Accuracy: 0.6369531154632568\n",
      "Loss: 0.8993628621101379 Accuracy: 0.6440558433532715\n",
      "Loss: 0.8801581859588623 Accuracy: 0.6624218821525574\n",
      "Loss: 0.7779927253723145 Accuracy: 0.6729687452316284\n",
      "Loss: 0.8310056924819946 Accuracy: 0.6853125095367432\n",
      "Loss: 0.6434568762779236 Accuracy: 0.6846768856048584\n",
      "Loss: 0.8167835474014282 Accuracy: 0.7133593559265137\n",
      "Loss: 0.7691630125045776 Accuracy: 0.7075781226158142\n",
      "Loss: 0.6804777383804321 Accuracy: 0.7116405963897705\n",
      "Loss: 0.7413195371627808 Accuracy: 0.7227101922035217\n"
     ]
    }
   ],
   "source": [
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "for step, (img_batch, lbl_batch) in enumerate(data):\n",
    "    if step > train_steps:\n",
    "        break\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(img_batch)\n",
    "        # loss format is generally: first argument targets, second argument outputs\n",
    "        xent = loss_fn(lbl_batch, logits)\n",
    "\n",
    "    # if you didn't build the model, it is important that you get the variables\n",
    "    # AFTER the model has been called the first time\n",
    "    varis = model.trainable_variables\n",
    "    grads = tape.gradient(xent, varis)\n",
    "      \n",
    "    opt.apply_gradients(zip(grads, varis))\n",
    "    \n",
    "    train_acc_metric(lbl_batch, logits)\n",
    "    \n",
    "    if not step % 100:\n",
    "        # this is different from before. there, we only evaluated accuracy\n",
    "        # for one batch. Now, we always average over 100 batches\n",
    "        print(\"Loss: {} Accuracy: {}\".format(xent, train_acc_metric.result()))\n",
    "        train_acc_metric.reset_states()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
